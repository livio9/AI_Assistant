import gradio as gr
import os
import time
from image_generate import image_generate
from mnist import image_classification
from chat import chat, chat_stream
from search import search
# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.

messages = []
current_file_text = None

def add_text(history, text):
    global messages
    user_input = {"role": "user", "content": text}
    messages.append(user_input)
    history = history + [(text, None)]
    return history, gr.update(value="", interactive=False)



def add_file(history, file):
    global messages
    global current_file_text
    if file.name.endswith(".png"):
        current_file_text = file.name
        classify_query = f"Please classify{current_file_text}"
        messages.append({"role": "user", "content": classify_query})

    history = history + [((file.name,), None)]
    return history

def bot(history):
    # æ™®é€šèŠå¤©æ¨¡å¼
    # global messages
    # # è°ƒç”¨ chat å‡½æ•°ç”Ÿæˆå›å¤
    # assistant_reply = chat(messages)
    
    # # æ›´æ–° history ä¸­æœ€åä¸€æ¡è®°å½•çš„ AI å›å¤éƒ¨åˆ†
    # history[-1][1] = assistant_reply
    
    # # è®°å½•æ–°çš„ assistant å›å¤åˆ° messages ä¸­
    # messages.append({"role": "assistant", "content": assistant_reply})
    
    # return history

    # æ ‡è®°æ˜¯å¦æµå¼è¾“å‡º
    flu = 1

    # æµå¼èŠå¤©æ¨¡å¼
    global messages
    if current_file_text is None:
        content = messages[-1]["content"]

        if content.startswith("/search"):
            # æå– /search æŒ‡ä»¤åçš„å†…å®¹
            search_query = content[len("/search "):]

            # è°ƒç”¨ search å‡½æ•°è·å–æœç´¢ç»“æœ
            search_result = search(search_query)

            # å°†æœç´¢ç»“æœæ›´æ–°åˆ° messages ä¸­
            messages.append({"role": "user", "content": search_result})

        # ç”Ÿæˆå›¾åƒåŠŸèƒ½ï¼ˆYUNYAN ZHAOï¼‰
        elif content.startswith("/image"):
            flu = 0
            img_query = content[len("/image "):]
            messages.append({"role": "user", "content": content})
            img_link = image_generate(img_query)
            messages.append({"role": "assistant", "content": f'<img src="{str(img_link)}" alt="Generated Image">'})
            # messages.append({"role": "assistant", "content": str(history[-1][1][0])})
            history[-1][1] = (img_link,)
            yield history

        # ä½¿ç”¨ chat_stream å‡½æ•°ç”Ÿæˆæµå¼å›å¤
        if flu:
            assistant_reply_stream = chat_stream(messages)
            assistant_reply = ""
            for chunk in assistant_reply_stream:
                assistant_reply += chunk["choices"][0]["delta"].get("content", "")
                history[-1][1] = assistant_reply
                yield history

            # è®°å½•å®Œæ•´çš„ assistant å›å¤åˆ° messages ä¸­
            messages.append({"role": "assistant", "content": assistant_reply})
    elif current_file_text.endswith(".png"):
        # print(current_file_text)
        reply_classify = image_classification(current_file_text)
        history[-1][1] = reply_classify
        yield history
        messages.append({"role": "assistant", "content": reply_classify})


with gr.Blocks() as demo:
    chatbot = gr.Chatbot(
        [],
        elem_id="chatbot",
        avatar_images=(None, (os.path.join(os.path.dirname(__file__), "avatar.png"))),
    )

    with gr.Row():
        txt = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="Enter text and press enter, or upload an image",
            container=False,
        )
        clear_btn = gr.Button('Clear')
        btn = gr.UploadButton("ğŸ“", file_types=["image", "video", "audio", "text"])

    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
        bot, chatbot, chatbot
    )
    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)
    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(
        bot, chatbot, chatbot
    )
    clear_btn.click(lambda: messages.clear(), None, chatbot, queue=False)

demo.queue()
demo.launch()
